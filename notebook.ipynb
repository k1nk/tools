{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e355df2d-ac50-44bb-bd2d-c74b0788e684",
    "_execution_state": "idle",
    "_uuid": "dd7d4793fa65476631f78441818c25832b98fb50"
   },
   "source": [
    "敵対的サンプルの作成\n",
    "\n",
    "ここでは、０から９のOCRイメージをmulticlass logistic regressionによって分類するモデルに対して、敵対的サンプルの作成を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d746e523-67f5-46b4-a0fc-8611cbc02e2d",
    "_uuid": "0b1a679918e749283c22f627d6df89f3af35e951"
   },
   "source": [
    "## Walktrough contents\n",
    "\n",
    "* データとパッケージの読み込み\n",
    "* 攻撃用のメソッドとクラス\n",
    "* Training the model\n",
    "* Non-Targeted-Attack: \n",
    "    * Maximizing the output-target discrepance\n",
    "    * Natural fooling targets (Reworked)\n",
    "* Targeted-Attack: \n",
    "    * One image example\n",
    "    * Natural vs non-natural fooling targets & accuracy score breakdown for all images (Reworked)\n",
    "* Comparison to Fast Gradient Method: \n",
    "    * Thoughts: Maximizing discrepance vs. minimizing likelihood\n",
    "* The Jacobian enters the door\n",
    "* Conclusion\n",
    "\n",
    "**Latest Changes:**\n",
    "* Rework: Natural vs non-natural fooling\n",
    "* Skip LDA as kernel has already too much content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cbbf0e2f-7721-4547-8943-c72c7b8b935c",
    "_uuid": "20f2087b01f05a02c802694920aa660e44d97bb0"
   },
   "source": [
    "## パッケージの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "bc70953a-0e83-4581-8390-e8bef8f3c092",
    "_execution_state": "idle",
    "_uuid": "1ca8c05008e02ffb425117e95e9b53221b2a3717"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets as dt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "from skimage.io import imread, imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X,y = dt.load_digits(return_X_y=True)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ee098565-4622-4023-8039-94952ad1c7bb",
    "_uuid": "e01fa46ec8ed77078d226543fe9f137baa4792c0"
   },
   "source": [
    "To see that are trained model can be good at prediction of original images but bad for perturbed I split the data into train and test. Then we can compare the prediction for original test data and perturbed test data. ;-)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c863d722-33b0-40cf-bac5-23ff40b0bf61",
    "_uuid": "f6ccc694a5a23c4599effb19e6ed99be37b588a9"
   },
   "source": [
    "## データの読み込み、内容の確認\n",
    "\n",
    "今回使うデータを読み込み、その先頭の内容を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "21c7aed6-1e25-4e1d-9cd1-e0b315ac309e",
    "_execution_state": "idle",
    "_uuid": "08fc0af13cc8650f7d25a2207a78e5c386fe1043",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"input/digit-recognizer/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "487b5a94-2ee7-4e8d-a6a1-2db33cf1e229",
    "_execution_state": "idle",
    "_uuid": "c6a722537925697fcd66c70d0827e6b3fa3d4e43"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] 指定されたファイルが見つかりません。",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5e5e675c5e7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msubprocess\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dir\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"input\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorenv\\lib\\subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[1;32m--> 316\u001b[1;33m                **kwargs).stdout\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorenv\\lib\\subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(input, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stdin'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPIPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorenv\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds)\u001b[0m\n\u001b[0;32m    674\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    677\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[1;31m# Cleanup if the child failed starting.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorenv\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m    953\u001b[0m                                          \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m                                          \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 955\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m    956\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m                 \u001b[1;31m# Child is launched. Close the parent's copy of those pipe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] 指定されたファイルが見つかりません。"
     ]
    }
   ],
   "source": [
    "from subprocess import check_output\n",
    "print(check_output([\"dir\", \"input\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##データの構造\n",
    "ラベル（label）は、数字の０~９を表します。pixcel0からpixcel783は、２８×２８の画像の値を表します。\n",
    "例えば、pixel31画像の上から２行目、左から４番目の画像の値を表します。28×(2-1)+(4-1)=31\n",
    "画像の値は、０~２５５で、値が少ない方がより明るく、多い方がより暗いことを表します。\n",
    "\n",
    "yはラベルの値とします。\n",
    "Xは、データdfからlabelの列を削除したものとします。\n",
    "そして、Xとyを訓練用データとテストデータに区分します。全体の４０％をテストデータとします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "692864db-8c5a-4cb5-ab38-7347364f05fd",
    "_execution_state": "idle",
    "_uuid": "0d9eae00137ebfc5f4bf37c24b7630491acc7059",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df.label.values\n",
    "X = df.drop(\"label\",axis=1).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cfb1e742-c6d1-4630-a170-c5d3fa658649",
    "_uuid": "5918a034cd5e580d744ba56597637cd9549972a1"
   },
   "source": [
    "テスト用データの最初の１５文字の内容を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "695f1427-1925-460f-b495-498795788572",
    "_execution_state": "idle",
    "_uuid": "6479e12ade27f0932ec149cad7b7fc488f8d12cf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAABeCAYAAABSKOctAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAnXq6YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2538cc4b4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig1, ax1 = plt.subplots(1,15, figsize=(15,10))\n",
    "for i in range(15):\n",
    "    ax1[i].imshow(X_test[i].reshape((28,28)))\n",
    "    ax1[i].axis('off')\n",
    "    ax1[i].set_title(y_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ba0d171f-788d-43cc-a17b-66a4ed6ab583",
    "_uuid": "744cee6d8f4ccf3f960e0365d4b6286a67327bc8"
   },
   "source": [
    "一部、人間にとっても判別しずらい文字があるようです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "31927fcd-d45f-42fc-82bc-32052e029601",
    "_execution_state": "idle",
    "_uuid": "c6a26adf8bf68097202c8df4f0bc26311aeb3456"
   },
   "source": [
    "## コード　attack用の関数とクラス\n",
    "\n",
    "As I don't like to fill this kernel with same code used for different cases again and again, I will store it here. I hope, this makes it also easier for you to play with this kernel if you like to fork :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "915db0f1-ae8c-407c-9c9b-9f76ec042b8c",
    "_uuid": "405f1b87ed32bf2a872e01be1493c25aa7745e3b"
   },
   "source": [
    "### Attack用関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "6529c8b8-bb06-483b-a5d5-648aebd388f6",
    "_execution_state": "idle",
    "_uuid": "5546e41f11c910868d1c83c0578aa1607c27ad67",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_output_weighted_weights(output, w):\n",
    "    for c in range(len(output)):\n",
    "        if c == 0:\n",
    "            weighted_weights = output[c] * w[c]\n",
    "        else:\n",
    "            weighted_weights += output[c] * w[c]\n",
    "    return weighted_weights\n",
    "\n",
    "def targeted_gradient(foolingtarget, output, w):\n",
    "    ww = calc_output_weighted_weights(output, w)\n",
    "    for k in range(len(output)):\n",
    "        if k == 0:\n",
    "            gradient = foolingtarget[k] * (w[k]-ww)\n",
    "        else:\n",
    "            gradient += foolingtarget[k] * (w[k]-ww)\n",
    "    return gradient\n",
    "\n",
    "def non_targeted_gradient(target, output, w):\n",
    "    ww = calc_output_weighted_weights(output, w)\n",
    "    for k in range(len(target)):\n",
    "        if k == 0:\n",
    "            gradient = (1-target[k]) * (w[k]-ww)\n",
    "        else:\n",
    "            gradient += (1-target[k]) * (w[k]-ww)\n",
    "    return gradient\n",
    "\n",
    "def non_targeted_sign_gradient(target, output, w):\n",
    "    gradient = non_targeted_gradient(target, output, w)\n",
    "    return np.sign(gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dee87868-c3dd-4fb3-b802-8164caca49a4",
    "_uuid": "e97e4ed951040c821ce85a591cb8c694ae66c7b4"
   },
   "source": [
    "### Attack用クラス\n",
    "クラスの初期化時に__init__でモデルを読み込みます。\n",
    "prepareメソッドで、モデルの訓練およびテストを行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "3ef66832-11f7-4a10-b20e-d69c74a43e4a",
    "_execution_state": "idle",
    "_uuid": "e414d07a3570fb6d0fe62103df3f700dafbcd258",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Attack:\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.fooling_targets = None\n",
    "        self.model = model\n",
    "    \n",
    "    def prepare(self, X_train, y_train, X_test, y_test):\n",
    "        self.images = X_test\n",
    "        self.true_targets = y_test\n",
    "        self.num_samples = X_test.shape[0]\n",
    "        self.train(X_train, y_train)\n",
    "        print(\"Model training finished.\")\n",
    "        self.test(X_test, y_test)\n",
    "        print(\"Model testing finished. Initial accuracy score: \" + str(self.initial_score))\n",
    "    \n",
    "    def set_fooling_targets(self, fooling_targets):\n",
    "        self.fooling_targets = fooling_targets\n",
    "        \n",
    "    def train(self, X_train, y_train):\n",
    "        self.model.fit(X_train, y_train)\n",
    "        self.weights = self.model.coef_\n",
    "        self.num_classes = self.weights.shape[0]\n",
    "\n",
    "    def test(self, X_test, y_test):\n",
    "        self.preds = self.model.predict(X_test)\n",
    "        self.preds_proba = self.model.predict_proba(X_test)\n",
    "        self.initial_score = accuracy_score(y_test, self.preds)\n",
    "    \n",
    "    def create_one_hot_targets(self, targets):\n",
    "        self.one_hot_targets = np.zeros(self.preds_proba.shape)\n",
    "        for n in range(targets.shape[0]):\n",
    "            self.one_hot_targets[n, targets[n]] = 1\n",
    "            \n",
    "    def attack(self, attackmethod, epsilon):\n",
    "        perturbed_images, highest_epsilon = self.perturb_images(epsilon, attackmethod)\n",
    "        perturbed_preds = self.model.predict(perturbed_images)\n",
    "        score = accuracy_score(self.true_targets, perturbed_preds)\n",
    "        return perturbed_images, perturbed_preds, score, highest_epsilon\n",
    "\n",
    "    def perturb_images(self, epsilon, gradient_method):\n",
    "        perturbed = np.zeros(self.images.shape)\n",
    "        max_perturbations = []\n",
    "        for n in range(self.images.shape[0]):\n",
    "            perturbation = self.get_perturbation(epsilon, gradient_method, self.one_hot_targets[n], self.preds_proba[n])\n",
    "            perturbed[n] = self.images[n] + perturbation\n",
    "            max_perturbations.append(np.max(perturbation))\n",
    "        highest_epsilon = np.max(np.array(max_perturbations))\n",
    "        return perturbed, highest_epsilon\n",
    "    \n",
    "    def get_perturbation(self, epsilon, gradient_method, target, pred_proba):\n",
    "        gradient = gradient_method(target, pred_proba, self.weights)\n",
    "        inf_norm = np.max(gradient)\n",
    "        perturbation = epsilon/inf_norm * gradient\n",
    "        return perturbation\n",
    "        \n",
    "    def attack_to_max_epsilon(self, attackmethod, max_epsilon):\n",
    "        self.max_epsilon = max_epsilon\n",
    "        self.scores = []\n",
    "        self.epsilons = []\n",
    "        self.perturbed_images_per_epsilon = []\n",
    "        self.perturbed_outputs_per_epsilon = []\n",
    "        for epsilon in range(0, self.max_epsilon):\n",
    "            print(\"calling attack with epsilon:\",epsilon)\n",
    "            perturbed_images, perturbed_preds, score, highest_epsilon = self.attack(attackmethod, epsilon)\n",
    "            self.epsilons.append(highest_epsilon)\n",
    "            self.scores.append(score)\n",
    "            self.perturbed_images_per_epsilon.append(perturbed_images)\n",
    "            self.perturbed_outputs_per_epsilon.append(perturbed_preds)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b633f74c-8833-4be7-aa78-09081f4b612d",
    "_uuid": "e466a4d6b44b9077874749bf986f7d4a3146ff33"
   },
   "source": [
    "## モデルを訓練する\n",
    "\n",
    "multiclass logistic regression　のモデルを用意します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "55e834b0-9fa4-4f2a-9a24-34130b54155e",
    "_execution_state": "idle",
    "_uuid": "cecf10684e01d0d1f70a7687a150f4af6961311c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', fit_intercept=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1af94c5e-20f2-4668-ad8e-09a6cf86d00e",
    "_uuid": "d005b92bd181ea337b3a75a10d42cc7a847aa063"
   },
   "source": [
    "用意したmodelをAttackクラスに渡して、Attackクラスのインスタンスを作成します。そして、prepareメソッドでモデルの訓練およびテストを行いまます。その際にテストデータを使った、当初のaccuracyを取得します。このスコアをのちにテストデータにノイズを加えることにより低下させます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "398d0ad7-42b6-4ebe-957d-f9a0a714fb51",
    "_execution_state": "idle",
    "_uuid": "5838fa53c94e550242436cc476ae963a8ab3442f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training finished.\n",
      "Model testing finished. Initial accuracy score: 0.910952380952\n"
     ]
    }
   ],
   "source": [
    "attack = Attack(model)\n",
    "attack.prepare(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "約９０％のデータが正しく分類されているようです。\n",
    "attack.imagesは、テスト用の画像データを表します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "ec2aa3f7-fe08-4406-8063-bb432a050181",
    "_uuid": "d2d870c2320fd5cb6c64caf1147201d452b390fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16800, 784)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8adb53ba-5d38-40af-9517-3cd58812fb6b",
    "_uuid": "6a7c8af89ecd0808a79764728fcb1426a0d0a020"
   },
   "source": [
    "\n",
    "Ok, around 90 percent of test data was classified correctly and for us this is sufficient to play with. In multiclass logistic regression the probability that the model outputs $y_{n}$ of $N$ inputs $x_{n}$ matches their targets $t_{n}$ is given by:\n",
    "\n",
    "$$ \n",
    "p(t|y(x,w)) = \\prod_{n=1}^{N} \\prod_{k=1}^{K} y_{n,k}^{t_{n,k}} \n",
    "$$\n",
    "\n",
    "We assumed that inputs and class memberships are independent and identically distributed. The target $t_{n}$ of one input $x_{n}$ is a vector with K elements following one-hot-encoding (the true label class is 1, all others are 0). Maximizing the probability of matches above is also called the maximum likelihood approach. Each class in a multiclass logistic regression has its own weight vector and inputs are passed with weights through the softmax function to obtain the model output:\n",
    "\n",
    "$$ \n",
    "y_{n,k} = \\frac{\\exp(w_{k}^{T}x_{n})} {\\sum_{c=1}^{K}\\exp(w_{c}^{T}x_{n})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "52517038-c7c7-41cf-8950-26811694e2ee",
    "_uuid": "aa07a74d3bf760b92e8f3ddc396351cf42747922"
   },
   "source": [
    "attack.weightsは、モデルの重みを表します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "f50ad7d2-3b7c-4371-ab52-b55fff8efe2e",
    "_execution_state": "idle",
    "_uuid": "6278622538769c377689abf4036898cd43c8094a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 784)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = attack.weights\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "e444b1be-b561-49dc-9786-043f3b3dcdff",
    "_execution_state": "idle",
    "_uuid": "9f48657c0c7eeb5a088f0f75cfa6b3ef945b4efb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(np.unique(y_train))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "933989e0-004b-4b23-831d-9b7b0e264ca1",
    "_uuid": "c66d82eaa0038cba41f3bf9e8b43257dc21dd388"
   },
   "source": [
    "訓練用のデータに含まれるユニークなラベルの数は１０となっています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b6234953-94cc-48ff-9e27-7668f46e15e0",
    "_uuid": "8ce8c9c442f93f56d229e201ca7d8acc0c10b949"
   },
   "source": [
    "## Non-targeted Attack:正しいラベルへ分類されないようにする\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0400e84b-2aa9-4a0d-9770-96b3699e2d1c",
    "_uuid": "b51ccee09183e6aee7a87e410d0fad7f02260b48"
   },
   "source": [
    "### ノイズ（摂動）を加える"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "243afa5b-4e4e-45b9-831d-dda132b165d7",
    "_uuid": "0b5f78e4456a379e6fe8c62fad239ade0a6aa789"
   },
   "source": [
    "まず、テストデータのイメージに加えるノイズを計算します。そのために、To do this we have to transform our true targets to one-hot-targets and call attack :-). As I want to see, how much epsilon we need to create a good breakdown, I use the attack_to_max_epsilon method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "dde231aa-12b5-47f2-8de0-c1cfdd60d519",
    "_execution_state": "idle",
    "_uuid": "c82590af33833f2567f0206f3f6137471fee1bf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling attack with epsilon: 0\n",
      "calling attack with epsilon: 1\n",
      "calling attack with epsilon: 2\n",
      "calling attack with epsilon: 3\n",
      "calling attack with epsilon: 4\n",
      "calling attack with epsilon: 5\n",
      "calling attack with epsilon: 6\n",
      "calling attack with epsilon: 7\n",
      "calling attack with epsilon: 8\n",
      "calling attack with epsilon: 9\n",
      "calling attack with epsilon: 10\n",
      "calling attack with epsilon: 11\n",
      "calling attack with epsilon: 12\n",
      "calling attack with epsilon: 13\n",
      "calling attack with epsilon: 14\n",
      "calling attack with epsilon: 15\n",
      "calling attack with epsilon: 16\n",
      "calling attack with epsilon: 17\n",
      "calling attack with epsilon: 18\n",
      "calling attack with epsilon: 19\n",
      "calling attack with epsilon: 20\n",
      "calling attack with epsilon: 21\n",
      "calling attack with epsilon: 22\n",
      "calling attack with epsilon: 23\n",
      "calling attack with epsilon: 24\n",
      "calling attack with epsilon: 25\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-41f47a408692>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mattack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_one_hot_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mattack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattack_to_max_epsilon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnon_targeted_gradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mnon_targeted_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-87904fb9e449>\u001b[0m in \u001b[0;36mattack_to_max_epsilon\u001b[1;34m(self, attackmethod, max_epsilon)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_epsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"calling attack with epsilon:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m             \u001b[0mperturbed_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperturbed_preds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhighest_epsilon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattackmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilons\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhighest_epsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-87904fb9e449>\u001b[0m in \u001b[0;36mattack\u001b[1;34m(self, attackmethod, epsilon)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mattack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattackmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mperturbed_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhighest_epsilon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperturb_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattackmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mperturbed_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperturbed_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrue_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperturbed_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-87904fb9e449>\u001b[0m in \u001b[0;36mperturb_images\u001b[1;34m(self, epsilon, gradient_method)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mperturb_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mperturbed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mmax_perturbations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "attack.create_one_hot_targets(y_test)\n",
    "attack.attack_to_max_epsilon(non_targeted_gradient, 30)\n",
    "non_targeted_scores = attack.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a33b845c-0dc6-4d49-babb-50ffa5572520",
    "_execution_state": "idle",
    "_uuid": "ab8237ddeeca26485ee6e2e66bb1a4a95ecb32cb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(attack.epsilons, attack.scores, 'g*')\n",
    "plt.ylabel('accuracy_score')\n",
    "plt.xlabel('epsilon')\n",
    "plt.title('Accuracy score breakdown - non-targeted attack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "babf47d9-5add-4453-abe2-0cbd478966c8",
    "_uuid": "8ef513bea5cba8730cf15bd8abfc2ae7bb8a5a05"
   },
   "source": [
    "Uii, the threshold is given by a max of 16 pixel that are allowed to be added as perturbation per pixel per image. Given this $\\epsilon$ we would end up with a model that still predicts around 40 % correctly. If we would use max $\\epsilon=30$ the model would fail with almoast 90 % digits in the test set :-) . Let's have a look at one example of successful fooling for a range of epsilons until max of $\\epsilon = 16$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "36a77cd4-90c1-4ed3-bb76-a153af0bf06a",
    "_execution_state": "idle",
    "_uuid": "5488992c63f23a1ceb054d9b2abb14461f042bdb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eps = 16\n",
    "attack.epsilons[eps]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8be8bee7-e497-4dce-b04a-c69fcb1da737",
    "_uuid": "eb6d99993025adab182e73bbed6d67192e291ddc"
   },
   "source": [
    "We need the perturbed images as well as the fooling results of that epsilon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "50bde7ea-a653-4358-8846-b09a2d98d4ed",
    "_execution_state": "idle",
    "_uuid": "6a63f4acd8e7318059d97e86cfaef351fdb71f34",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_images = attack.perturbed_images_per_epsilon[eps]\n",
    "example_preds = attack.perturbed_outputs_per_epsilon[eps]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "17bd2225-5ee1-4515-9858-8f50f2eb1be4",
    "_uuid": "d28e5a106f3aaf1eb306dadc379ed60e4a61997c"
   },
   "source": [
    "And I will store results in a pandas dataframe such that we can easily find successful foolings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "49cd9f0c-0ebc-44cf-a1ae-86ac6deb4bd6",
    "_execution_state": "idle",
    "_uuid": "5e50d8a32c92a86fe3d93580a3828da32cadfe6d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_results = pd.DataFrame(data=attack.true_targets, columns=['y_true'])\n",
    "example_results['y_fooled'] = example_preds\n",
    "example_results['y_predicted'] = attack.preds\n",
    "example_results['id'] = example_results.index.values\n",
    "example_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2cff8ade-eef2-4f85-ac5a-411f6af2cbe6",
    "_execution_state": "idle",
    "_uuid": "628ef80fd435adb9fd9d9fb602c7b2def02f9c1b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "success_df = example_results[example_results.y_fooled != example_results.y_true]\n",
    "success_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5b791596-caec-4a08-a7f9-e16f75d01f79",
    "_uuid": "c2446d6390df0c59acf1d81492b1f6b6f5fb1455"
   },
   "source": [
    "Ok, we will choose one of these successful examples and plot its related perturbed image over a range of epsilons: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "48f68809-43a7-4a24-b949-c093970a9437",
    "_execution_state": "idle",
    "_uuid": "ba80cab01d80d8b5685e98ce5e3b225e15d1cf20",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_id = success_df.id.values[0]\n",
    "example_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "850ec3a5-a332-41aa-b7cd-3d435336ddd7",
    "_execution_state": "idle",
    "_uuid": "16915e0cc91c906803a61640ba26142591091280",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots(4,4, figsize=(10,10))\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        image = attack.perturbed_images_per_epsilon[i*4 + j][example_id]\n",
    "        y_fooled = attack.perturbed_outputs_per_epsilon[i*4 + j][example_id]\n",
    "        epsilon = attack.epsilons[i*4 +j]\n",
    "        ax2[i,j].imshow(image.reshape((28,28)))\n",
    "        ax2[i,j].axis('off')\n",
    "        ax2[i,j].set_title(\"true: \" + str(y_test[example_id]) + \", fooled: \" + str(y_fooled)  + \"\\n\" \n",
    "                           + \"epsilon: \" + str(epsilon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8ef83b99-c96d-4291-bbbf-ffaddca88ab9",
    "_uuid": "123f61520916def391c1233e0416d58b772f3791"
   },
   "source": [
    "Yeah! :-) We can still see the true target and not the fooling target. That's amazing. But we can also see, that the background has increased intensitiy. Let's visualize the difference between the original true label and the adversarial image for $\\epsilon = 16$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f0291249-2815-4c1e-bc6a-901c2bdd2f47",
    "_execution_state": "idle",
    "_uuid": "bdbe09c9e03efde2af49099c95cd83645db68e5b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, (axA, axB, axC) = plt.subplots(1, 3, figsize=(15,5))\n",
    "axB.imshow(example_images[example_id].reshape((28,28)), cmap='Greens')\n",
    "axB.set_title(\"Non-targeted attack result: \" + str(example_preds[example_id]))\n",
    "axA.imshow(X_test[example_id].reshape((28,28)), cmap='Greens')\n",
    "axA.set_title(\"True label: \" + str(y_test[example_id]))\n",
    "axC.imshow((X_test[example_id]-example_images[example_id]).reshape((28,28)), cmap='Reds')\n",
    "axC.set_title(\"Perturbation: epsilon 16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2150fd1a-5717-4a4e-8b1b-1689dd3c03bc",
    "_execution_state": "idle",
    "_uuid": "3c3061bc08977563423846b218ee903ec2f6a9e9"
   },
   "source": [
    "### The gradient travel guide - natural fooling targets\n",
    "\n",
    "I'm happy that it was possible to fool our model but it's still diffuse and unclear where the one-step-gradient guides us through (remember we do not iterate with gradient ascent, we just take one step and size is given by strength of gradient times eta). I assume that some numbers are closer to each other in weight space than to others. As the model training draws decision boundaries dependent on the quality of the input data and flexibility of model architecture, there will be regions where a 3 is not predicted as 3 but as 8. Those regions where the model makes an incorrect prediction. And I think, that there are preffered numbers to be wrong predictions given a digit input image. Perhaps the fooling gradients drives us to those \"natural\" fooling target numbers? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9a58deac-8ede-48a2-a353-1614d7edae56",
    "_execution_state": "idle",
    "_uuid": "dd50bcaf51f98491c2c517a6476d3b4e328c60cf",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(x='y_fooled', data=example_results[example_results.y_true != example_results.y_fooled])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cc733bdd-bb3f-46db-94ca-cdf7febabf36",
    "_uuid": "fa304a9daf1d4cbdd95a359e73ee5825c2ca7fd3"
   },
   "source": [
    "Ok, we see that 8 was selected most often as fooling target. But 9, 3, 5 and 2 have high counts as well in contrast to 0, 1, 6 and 7. If our assumption is true that the gradient drives us to targets where the model tends to fail in prediction we should see a similar pattern of counts for wrong predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9e46660d-99e9-460c-bcde-94c3d01c2251",
    "_execution_state": "idle",
    "_uuid": "c1dcda977d59668fa31b4882fec51b2930bb0086",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wrong_predictions = example_results[example_results.y_true != example_results.y_predicted]\n",
    "wrong_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4c5562f2-cbcb-42f7-b33b-3092649ad3a4",
    "_execution_state": "idle",
    "_uuid": "63da90b5890b9b4a4a9efc9b49a4f557c6ca1523",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bb259da0-7721-4180-b833-80efe1537ab6",
    "_uuid": "30f0bfc8f3a49e89098cdb1f40c584dcdb6a9d23"
   },
   "source": [
    "Ok, so out of 16800 samples, the model failed to predict around 1600. That's why our intital accuracy score is close to 90 % (means 10 % failing). Now, which digit was selected as wrong prediction result most often?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "131fdbd7-9e90-4f50-b46d-129403e9fd73",
    "_execution_state": "idle",
    "_uuid": "989368c698badd3b824ecfaf04a57db059547cf1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(x='y_predicted', data=wrong_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cfe6a812-c679-48a0-8a82-627b305ed044",
    "_uuid": "dc278495378b9a565803f6cba55fecf15d404108"
   },
   "source": [
    "Yes, that's the same pattern as for the fooling targets. As this is caused by the difficulty of our model to draw good decision boundaries we should see this pattern as well for the true labels of those digits that were wrong predicted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ec52935f-ec3e-4966-87f5-3474eebd23e9",
    "_execution_state": "idle",
    "_uuid": "d0486299bde081f8ea34bc85a2a5a1fba67716bb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(x='y_true', data=wrong_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f048ecfa-f8ae-4215-93bb-74fbb1fe433e",
    "_uuid": "789e40f6a6dc68011d10012b410c8a0571d493bc"
   },
   "source": [
    " Now I want to see it in more detail: Which are the natural fooling targets (for successful foolings) for each digit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "14fc9785-cc79-453a-af63-c6391bcd47dc",
    "_execution_state": "idle",
    "_uuid": "de0c2c38c9dd0168195a71791e2387fbee15c23a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attacktargets = example_results[example_results.y_true != example_results.y_fooled].groupby('y_true').y_fooled.value_counts().unstack()\n",
    "attacktargets = attacktargets.fillna(0.0)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.heatmap(attacktargets, annot=True, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7cf3f365-9e98-42c8-b67a-1de9c70cde0f",
    "_uuid": "e9f66adbc62e0a68324ca0e2cf513a964a767490"
   },
   "source": [
    "We found out that each digit has its natural fooling target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6e1cc309-133e-4bd6-a24d-8efddfe6a4ac",
    "_execution_state": "idle",
    "_uuid": "7d3e0012dba9671732f913a6663ee66f0810e8c1"
   },
   "source": [
    "## Targeted-Attack\n",
    "\n",
    "We have seen that fooling the multiclass logistic regression model was easy with gradient ascent and the only cumbersome part was to calculate the gradient with respect to the inputs of our discrepance function. Instead of forcing the function to yield the maximum discrepance we could have also construct it such that outputs have to match a specific false target. To emphasize the difference to the true target $t_{n,k}$ let's call it $f_{n,k}$ for \"fooling\" target.\n",
    "\n",
    "$$ D(t|y(w,x)) = \\prod_{n=1}^{N} \\prod_{k=1}^{K} y_{n,k}^{f_{n,k}} $$\n",
    "\n",
    "Luckily we do not have to calculate everything again, the only thing that changes is:\n",
    "\n",
    "$$ \\frac {\\partial D}{\\partial y_{k}}  = \\frac {f_{k}} {y_{k}} $$\n",
    "\n",
    "Consequently we have:\n",
    "\n",
    "$$ \\nabla_{x} \\log D = \\sum_{k=1}^{K} f_{k} \\cdot  (\\vec{w}_{k} - \\sum_{c=1}^{K} y_{c} \\vec{w}_{c}) $$\n",
    "\n",
    "$$ x_{p, m} = x_{m} + \\eta \\sum_{k=1}^{K} f_{k} \\cdot  (\\vec{w}_{k} - \\sum_{c=1}^{K} y_{m,c} \\vec{w}_{c}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ffc82675-14f0-4126-bb99-e262b9fb52d2",
    "_execution_state": "idle",
    "_uuid": "54b35dc38386b547d6cfa20d0687f7e978afbb0a"
   },
   "source": [
    "### One example image\n",
    "\n",
    "To play around, let's select one input of $X_{test}$ and try to make targeted attacks for each class $f_{k}$ except for the true label target $t_{k}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "01cbc8ce-8e8f-4aea-82be-100b1307c7af",
    "_execution_state": "idle",
    "_uuid": "4bb0ae6ecea99b47625cf6281b5303121423419e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example = X_test[0]\n",
    "imshow(example.reshape((28,28)), cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4e8196c3-7cd2-4834-9b32-e1d4f2e27e80",
    "_execution_state": "idle",
    "_uuid": "879b9b408c0b8335f7edbb349c8eab8ee6e191af",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"true label target: \" + str(y_test[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3449159e-682e-43cc-b71d-a35482c444f1",
    "_execution_state": "idle",
    "_uuid": "9b6b79a28d807bb217b015a77a1f1f6a0a7d9620"
   },
   "source": [
    "### Generating the fooling/attack classes and targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f46439a4-e4e0-44bf-bd87-14c973e562e4",
    "_uuid": "e8628614022112c07fa5852473073d3246278a60"
   },
   "source": [
    "First of all, we need some fooling targets. For our example digit all others are possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f57b8693-1ad2-4d39-a294-817c9e3a8978",
    "_execution_state": "idle",
    "_uuid": "e1b72b65d3b659f2357a8cbab394f6bbddc93793",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fooling_classes = []\n",
    "for k in range(num_classes):\n",
    "    if k != y_test[0]:\n",
    "        fooling_classes.append(k)\n",
    "fooling_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ae25c0d1-e37e-4a91-a2db-0cc1c170a46b",
    "_execution_state": "idle",
    "_uuid": "e09fb9f938373bf83202a1c195bea8c4610b7a77",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foolingtargets = np.zeros((len(fooling_classes), num_classes))\n",
    "for n in range(len(fooling_classes)):\n",
    "    foolingtargets[n,fooling_classes[n]] = 1\n",
    "foolingtargets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "70e8c3eb-e339-40d0-ac5a-4f83af964fe1",
    "_execution_state": "idle",
    "_uuid": "1714f1cc23e02378f8f96f5a9af7d4cb51dc4946"
   },
   "source": [
    "### Attacking the model\n",
    "\n",
    "I will force the attack to success by allowing an epsilon high enough to yield all targets. This way we can still find out, if we can see the true label or the fooling target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c3398542-d3d2-41ec-938a-bbfed255a4f7",
    "_execution_state": "idle",
    "_uuid": "87836dd1f87fec6af354847670837f409e7b46c2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eps=100\n",
    "targeted_perturbed_images = []\n",
    "targeted_perturbed_predictions = []\n",
    "for fooling_target in foolingtargets:   \n",
    "    targeted_perturbation = attack.get_perturbation(eps, targeted_gradient, fooling_target, attack.preds_proba[0])\n",
    "    targeted_perturbed_image = X_test[0] + targeted_perturbation\n",
    "    targeted_perturbed_prediction = attack.model.predict(targeted_perturbed_image.reshape(1, -1))\n",
    "    targeted_perturbed_images.append(targeted_perturbed_image)\n",
    "    targeted_perturbed_predictions.append(targeted_perturbed_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b9dd623f-fcd7-4070-b2bb-8ee32cb2b40f",
    "_execution_state": "idle",
    "_uuid": "b0adc609f7fc895e156f5e116cdc9ab7d4ee412d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targeted_perturbed_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6137de98-1c0a-4a38-a0ed-13996d77a0fd",
    "_execution_state": "idle",
    "_uuid": "3ba45c5c8d76cca2bc974c671c1b9032d9848fbc",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig3, ax3 = plt.subplots(3,3, figsize=(9,9))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax3[i,j].imshow(targeted_perturbed_images[i*3+j].reshape((28,28)))\n",
    "        ax3[i,j].axis('off')\n",
    "        ax3[i,j].set_title(\"fooling result: \" + str(targeted_perturbed_predictions[i*3+j][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "eb3f4a08-6a55-45c9-952f-e8d6c960390a",
    "_uuid": "1f2d42f2405a6a7eb8a784503e0e0ceec3887240"
   },
   "source": [
    "Even though we can see high background noise the true label is not destroyed. I can still see the true label with my eyes whereas the model predicts the desired fooling target (0 to 9, except true label). :-) That's cool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f46b17bb-e310-4baf-ad1d-8645589f2188",
    "_uuid": "7ba37092db956441bf5010d86e0c671f54ce2fc2"
   },
   "source": [
    "## Natural vs. non-natural targeted attack\n",
    "\n",
    "Now, I like to see what happens with the accuracy score if we fool the model for each image in the test set. \n",
    "By analyzing non-targeted attacks we found that some digits are more used as \"fooling\" target than others and that each digit has its fooling digit counterpart. I assume that fooling takes place in regions where the model fails to draw good decision boundaries. Using targeted attack we should see that we can breakdown the accuracy score easier with natural fooling targets than with the other digits. Let's try this! :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0838f111-c757-4536-a517-b0b3c1b89b3e",
    "_uuid": "e826c6dd80d198cdd8096523720d5faf8cd5f18f"
   },
   "source": [
    "### Prepare natural and non-natural fooling targets\n",
    "\n",
    "The gradient travel guide showed us the occurences of fooling target digits for each true digit. The highest count stands for the natural fooling target whereas the lowest corresponds to the non-natural fooling target. Given the heatmap we could create the targets by argmin and argmax per row (y_true) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6943db4c-5be7-4280-b8ee-6f779e426e38",
    "_execution_state": "idle",
    "_uuid": "919feed729201ee23dc3a99615d533b26b5856f1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(attacktargets, annot=True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8293b1f1-7370-4153-b34e-42ad7cd79d15",
    "_execution_state": "idle",
    "_uuid": "daa73a73256512bb2a7a4b8b1fa8f9227253e823",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "natural_targets_dict = {}\n",
    "non_natural_targets_dict = {}\n",
    "for ix, series in attacktargets.iterrows():\n",
    "    natural_targets_dict[ix] = series.argmax()\n",
    "    non_natural_targets_dict[ix] = series.drop(ix).argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4a90cedb-4b1c-49cb-a6e0-56027dbad74d",
    "_execution_state": "idle",
    "_uuid": "2a8234e379b8c3b4394eeb72d75d49718287c761",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "natural_targets_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "feeada47-b155-4091-b826-395503edb676",
    "_execution_state": "idle",
    "_uuid": "805809275409c6b68ae9c6ebbbe83e0df33c0668",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "natural_foolingtargets = np.zeros((y_test.shape[0]))\n",
    "non_natural_foolingtargets = np.zeros((y_test.shape[0]))\n",
    "\n",
    "for n in range(len(natural_foolingtargets)):\n",
    "    target = y_test[n]\n",
    "    natural_foolingtargets[n] = natural_targets_dict[target]\n",
    "    non_natural_foolingtargets[n] = non_natural_targets_dict[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "16269dbf-42e0-4ba4-8825-4c17b3d611e6",
    "_execution_state": "idle",
    "_uuid": "acf9f375aa4bb06fbb86f77c9ad3c70e12801ae5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attack.create_one_hot_targets(natural_foolingtargets.astype(np.int))\n",
    "attack.attack_to_max_epsilon(targeted_gradient, 30)\n",
    "natural_scores = attack.scores\n",
    "attack.create_one_hot_targets(non_natural_foolingtargets.astype(np.int))\n",
    "attack.attack_to_max_epsilon(targeted_gradient, 30)\n",
    "non_natural_scores = attack.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "65790a5f-014f-41ff-adfc-f82feb60f10e",
    "_uuid": "fe838b01e4b3114f689bd765dc010cb3d0d5e1a7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(attack.scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4ade18c0-0b84-438d-9605-f5f11a30f3bf",
    "_execution_state": "idle",
    "_uuid": "9f8203a7bfd048766726505ebcb2532e202a6580",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "nf, = plt.plot(attack.epsilons, natural_scores, 'g*', label='natural fooling')\n",
    "nnf, = plt.plot(attack.epsilons, non_natural_scores, 'b*', label='non-natural fooling')\n",
    "plt.legend(handles=[nf, nnf])\n",
    "plt.ylabel('accuracy_score')\n",
    "plt.xlabel('epsilon')\n",
    "plt.title('Accuracy score breakdown: natural vs non-natural targeted attack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "10385e49-5501-4d40-9293-71938a008c36",
    "_uuid": "b343bb2b2854b90c82928d146c62564f42174255"
   },
   "source": [
    "Ahhh! :-) We can clearly see that it was easier to fool the model with natural fooling targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "656a9170-d3b0-464f-8a7c-349632b2bf67",
    "_execution_state": "idle",
    "_uuid": "19380ce6ecf0fc1f64a55207583add0615ef2747"
   },
   "source": [
    "## Comparison to Fast Gradient Method\n",
    "\n",
    "\n",
    "So far we have used gradient ascent to maximize the probability of no-matches (non-targeted & targeted) and we derived the gradient with respect to inputs for objectives that are only slightly changed in comparison to the model defining likelihood function. This way we are very close to the Fast Gradient Method given in the cleverhans library:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "da3e76db-12e7-4bd4-b594-fd029e0890ac",
    "_uuid": "8be0d6952f92c88c586cd61ec08675a09c215693"
   },
   "source": [
    "* Maximizing probability of no-matches:\n",
    "\n",
    "$$ x_{p, m} = x_{m} + \\delta x_{m} = x_{m} + \\eta \\cdot \\nabla_{x_{m}} D(f_{m}|y_{m}(x_{m},w)) $$\n",
    "\n",
    "* Fast Gradient Method:\n",
    "\n",
    "$$ x_{p,m} = x_{m} + \\delta x_{m} = x_{m} + \\eta \\cdot sign (\\nabla_{x_{m}} J(w,x,y)) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d9c91b82-2ff7-49f9-b099-98e444af8d82",
    "_uuid": "a3af92bcbc0f0ae602716183f4f37218811c6034"
   },
   "source": [
    "Whereas $J(w,x,y)$ stands for the cost function used to train the model.  In many cases this is $E=- \\log (L(t|y(x,w))$, the negative log likelihood function. One might think that this should also be the case for this example and that we could have also simply maximize the cost funtion. As this would be the same as to minimize the log-likelihood, one might think:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e038b6f2-6d71-42d9-abc9-f7e5b91e2eeb",
    "_uuid": "27415f6b36be921b21890934bfa339510fc9e130"
   },
   "source": [
    "** ... instead of defining a discrepance function one could have also just minimize the likelihood function to yield the lowest probability of matches... **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e665c999-2d12-4411-9a78-a245564b251c",
    "_uuid": "df31b56c77c8180a9d64b30d4fcd7b3c71cc21f8"
   },
   "source": [
    "Ohoh! Is this true? Sounds so nice, but... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d7364d34-f7a3-45cd-a64f-4ff1873c2e1c",
    "_uuid": "663edc31462ec122efef66fc3e09c87da37dd2aa"
   },
   "source": [
    "### Maximizing discrepance = minimizing likelihood?\n",
    "\n",
    "Normally we use the likelihood to maximize the probability and we want to count those outputs $y_{n,c}$ related to target-values of $t_{n,c}=1$. Look at one example image $m$ that belongs to class 2 of 3, then for this one we would have:\n",
    "\n",
    "$$ l = y_{1}^{0} * y_{2}^{1} * y_{3}^{0} = y_{2} $$\n",
    "\n",
    "Hence this image contribute to the overall product over $n$ by a factor of $y_{2}$. Consequently each image $n$ would give us a y-factor of its true class whereas all the others only give us a factor of 1 such that it does not disturb our nice probability. If we would now use the same likelihood to represent the probability of no-matches we encounter a problem: To minimize the likelihood the only thing that can be done now is to set $y_{2}=0$ for image m. We would do this for all outputs that enter the likelihood by themselves. But what is with all the others? What to do with $y_{1}$ and $y_{3}$ for image m? Looking for a minimum of $y_{2}$ we could select anything for $y_{1}$ and $y_{3}$ as they just stay 1. That's ill-defined in contrast to our discrepance probability. There the situation for image m would look like this:\n",
    "\n",
    "$$ l = y_{1}^{1} * y_{2}^{0} * y_{3}^{1} = y_{1} * y_{3} $$\n",
    "\n",
    "And also our targeted-attack looks well for image m, if we define class 1 as our fooling class:\n",
    "\n",
    "$$ l = y_{1}^{1} * y_{2}^{0} * y_{3}^{0} = y_{1} $$\n",
    "\n",
    "We have made sure that only those output-values enter the likelihood that are not related to the true target and we made sure that they carry their values and not just a value of 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a1730861-920b-4044-a474-5db79f67c644",
    "_uuid": "4dbcf9cee5ca5f8d8f73759bdcb938707a7648af"
   },
   "source": [
    "## Comparison to \"discrepance\" Gradient Sign Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d9478884-e873-47a1-b0cd-8cb0ca7b1903",
    "_uuid": "0e25368e2d4f51105e839fcd2af4b5dcbd8a6827"
   },
   "source": [
    "Some small experiment: Let's only take the sign of the gradient of our attack. I think we will not be as goog as we could be with the full gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b095d974-2401-4700-adef-86cbeeffa4e6",
    "_execution_state": "idle",
    "_uuid": "24daf535a94bd1672f205ca6ad71ccbb74bd6da7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attack.create_one_hot_targets(y_test)\n",
    "attack.attack_to_max_epsilon(non_targeted_sign_gradient, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d19b486e-f624-42c0-a307-88d5912e0950",
    "_execution_state": "idle",
    "_uuid": "3341d04deed2974333d470355c8ae076bed038d1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "gm, = plt.plot(attack.epsilons, non_targeted_scores, 'g*', label='gradient method')\n",
    "gsm, = plt.plot(attack.epsilons, attack.scores, 'r*', label='gradient sign method')\n",
    "plt.ylabel('accuracy_score')\n",
    "plt.xlabel('eta')\n",
    "plt.legend(handles=[gm, gsm])\n",
    "plt.title('Accuracy score breakdown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "34483793-364e-4b4a-a867-c12cc02bdc04",
    "_uuid": "247084eaf01a5d3332b528406c95479eee3535c5"
   },
   "source": [
    "Uiih!! :-o That's a surprise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7d8b9f78-bcd4-41f2-9813-76a1be9d0099",
    "_uuid": "0a6ae56d84ff05f1bd1f02e5b2d9cf18035e573d"
   },
   "source": [
    "### One step further: The Jacobian matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a3c96afd-1af4-434a-a691-8cfe3dfa65e0",
    "_uuid": "8c5b9b219742522eee2ace9421d6da593f4c18f3"
   },
   "source": [
    "What if we would use the likelihood instead of the discrepance function to yield the perturbations? If you look at the equations, you can find a clear similarity:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3d8d7d9d-7df9-451c-91ad-60242feb6551",
    "_uuid": "6bc9c29e03fa367f93cf1751aa3ba2c24152c5d0"
   },
   "source": [
    "$$ D(t|y(w,x)) = \\prod_{n=1}^{N} \\prod_{k=1}^{K} y_{n,k}^{f_{n,k}} $$\n",
    "\n",
    "$$ \\nabla_{x} \\log D = \\sum_{k=1}^{K} f_{k} \\cdot  (\\vec{w}_{k} - \\sum_{c=1}^{K} y_{c} \\vec{w}_{c}) $$\n",
    "\n",
    "$$ L(t|y(x,w)) = \\prod_{n=1}^{N} \\prod_{k=1}^{K} y_{n,k}^{t_{n,k}} $$\n",
    "\n",
    "$$ \\nabla_{x} \\log L = \\sum_{k=1}^{K} t_{k} \\cdot  (\\vec{w}_{k} - \\sum_{c=1}^{K} y_{c} \\vec{w}_{c}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a2da1ca7-574a-407d-b1e2-ba620f42219c",
    "_uuid": "9eeac0d6ee534a03c0a5e5a76e0d22f546dcf7f0"
   },
   "source": [
    "The difference is the use of either the true label $t_{n,k}$ or the fooling target $f_{n,k}$. What remains the same is the gradient of output $y_{k}$ of class $k$ with respect to all features $x$ (pixels) of one single image.\n",
    "\n",
    "$$ \\frac {\\partial y_{k}}{\\partial x} =  y_{k} \\vec{w}_{k} - y_{k} \\cdot \\sum_{c=1}^{K} y_{c} \\vec{w}_{c}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "722c14a7-648c-4b39-aef4-a6e817996a91",
    "_uuid": "04b3504d535ae970f2618641aa011f71b3a301ff"
   },
   "source": [
    "Taking the derivative of the outputs for each class $\\partial y_{k}$ with respect to the input features $\\partial x_{d}$ (with d in range for 1 to 64 pixel) we have arrived at the **Jacobian matrix**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "099caa15-4ee1-4345-9080-d8f87df06941",
    "_uuid": "3b08e92739c65005b30f31743b0c3a39afeb4b53"
   },
   "source": [
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial y_{1}}{\\partial x_{1}}\t& \\frac{\\partial y_{1}}{\\partial x_{2}}\t& \\dots\t & \\frac{\\partial y_{1}}{\\partial x_{64}}     \\\\\n",
    "\\frac{\\partial y_{2}}{\\partial x_{1}}\t& \\frac{\\partial y_{2}}{\\partial x_{2}} \t& \\dots  & \\frac{\\partial y_{2}}{\\partial x_{64}} \t  \\\\\n",
    "\\vdots\t& \\vdots \t& \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial y_{10}}{\\partial x_{1}} \t& \\dots & \\dots\t & \\frac{\\partial y_{10}}{\\partial x_{64}}\n",
    "\\end{bmatrix}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d365aa22-e254-48ac-ba81-3a5db6fe7309",
    "_uuid": "a2a4bafccaba68084229e3781c92505de5fdebb9"
   },
   "source": [
    "Now, in each row we have one vector of $\\frac {\\partial y_{k}}{\\partial x}$. But that's not all! Have a closer look at the equations of $ \\nabla_{x} \\log L $ and $ \\nabla_{x} \\log D$. What are $t_{n,k}$ and $f_{n,k}$ doing here? ...\n",
    "\n",
    "They are working like a mask. :-)\n",
    "\n",
    "...\n",
    "\n",
    "Not every class contributes to the gradient! As we use one-hot-encoding, only the class with the $1$ yields a summand which is not 0. Looking at the Jacobian this means that all rows are 0 except for the class that is represented by 1 in the encoding of $t_{n,k}$ or $f_{n,k}$. Let's call this specific class $\\hat{k}$, then we have:\n",
    "\n",
    "$$ \\nabla_{x} \\log D =  \\vec{w}_{\\hat{k}} - \\sum_{c=1}^{K} y_{c} \\vec{w}_{c} $$\n",
    "\n",
    "$$ \\nabla_{x} \\log L =  \\vec{w}_{\\hat{k}} - \\sum_{c=1}^{K} y_{c} \\vec{w}_{c} $$\n",
    "\n",
    "But take in mind: $\\hat{k}$ is different for the both equations: one is the fooling class and the other the true label class and of course they are not the same! :-)\n",
    "\n",
    "### Why could this be important?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fbfb53e5-5dd1-4ebb-9ab3-131507939312",
    "_uuid": "27c6a8abe59aff24c6d5b1260fee1c5ec3e298ff"
   },
   "source": [
    "This looks like playing with equations but we gained an insight: We have found that we could express the perturbation by a masking of the Jacobian matrix. The letter tells us more generally how the outputs of all classes change with input perturbations. This is already a hint that we could built attacks and defenses on approaches based on the Jacobian. Besides the Fast Gradient Attack you can find a Jacobian-based approach as well. Have fun to explore! :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e95daec7-22ea-4613-9050-a394d79017b5",
    "_uuid": "72e3f2e1b1baa83f51a1bec36578da3a27dec690"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "My public journey has come to end. I have still ideas to play with but this kernel is already too long for an introduction. Feel free to fork, try different epsilons, only use the sign method, use dimensionality reductions as influence property.... there is so much to do :-) . For me it was the first time to fool a machine learning model and I learnt:\n",
    "\n",
    "1. One could easily fool a model if one has access to the learned weights and by defining own objectives that maximize the discrepance between targets and model outputs. (One could also fool without knowing weights or model architecture, but that's another topic...)\n",
    "2. Fooling takes place in regions where the model fails to draw good decision boundaries which of course depends on the model architecture/flexibility but on the input data quality and preprocessing as well.\n",
    "3. Due to the fact that some inputs are closer to each other in meanings of decision boundaries, there exist natural and non-natural fooling targets.\n",
    "\n",
    "\n",
    "Have fun and good luck, so far :-)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
